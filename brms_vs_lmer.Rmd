---
title: "BRMS vs lmer comparison"
output:
  html_document:
    df_print: paged
---

```{r, results=F, messages=F, warning=F}
library(tidyverse)
library(lme4)
library(brms)
library(Hmisc)
```

```{r}
num_runs = 50
num_subjects = 100
parameter_range = 2
noise_and_RE_sd = 0.5
```

```{r}
logistic = function(x) {
  return(1/(1+exp(-x)))
}
```

# making some data and running models on it

```{r, results=F, messages=F, warning=F}

model_data = data.frame()
for (run in 1:num_runs) {
  set.seed(run)
  subject_ids = 1:num_subjects
  subject_random_intercepts = rnorm(length(subject_ids), 0, noise_and_RE_sd)
  subject_p1_random_slopes = rnorm(length(subject_ids), 0, noise_and_RE_sd)
  trials = 1:20
  condition = c("A", "B") # between subjects
  parameter_2_values = c("U", "V")
  
  data = expand.grid(trial=trials, subject_id=subject_ids) %>%
    mutate(condition=cut(subject_id, c(1, num_subjects/2, num_subjects), labels=condition, include.lowest=T),
           parameter_1=runif(n(), -1, 1),
           parameter_2=sample(parameter_2_values, n(), replace=T),
           random_intercept=subject_random_intercepts[subject_id],
           p1_random_slope=subject_p1_random_slopes[subject_id],
           noise=rnorm(n(), 0, noise_and_RE_sd))
  
  intercept = runif(1, -parameter_range, parameter_range)
  beta_p1 = runif(1, -parameter_range, parameter_range)
  beta_p2_is_V = runif(1, -parameter_range, parameter_range)
  beta_cond= runif(1, -parameter_range, parameter_range)
  beta_p1_x_cond = runif(1, -parameter_range, parameter_range)
  beta_pparameter_range_is_V = runif(1, -parameter_range, parameter_range)
  beta_p1_x_pparameter_range = runif(1, -parameter_range, parameter_range)
  betas = c(intercept, beta_p1, beta_cond, beta_p2_is_V, beta_p1_x_cond, beta_p1_x_p2)
  beta_names = c("(Intercept)", "parameter_1", "conditionB", "parameter_2V", "parameter_1:conditionB", "parameter_1:parameter_2V")
  
  # dv is a bernoulli trial
  
  data = data %>%
    mutate(
      logit = (intercept + (beta_p1 + p1_random_slope)*parameter_1 + beta_p2_is_V * (parameter_2 == "V") + beta_cond * (condition == "B") + beta_p1_x_cond * (parameter_1 * (condition == "B")) + beta_p1_x_p2 * (parameter_1 * (parameter_2 == "V"))),
      p = logistic(logit)) %>%
    rowwise() %>%
    mutate(outcome=rbinom(1, 1, p))
  
  # lmer
  this_warnings = c()
  withCallingHandlers({lmer_model = glmer(outcome ~ parameter_1 * (condition + parameter_2) + (1 + parameter_1 | subject_id), data, family=binomial)}, warning=function(w) {this_warnings <<- c(this_warnings, w)})
  lmer_failed = length(this_warnings) > 0
  temp = summary(lmer_model)
  this_warning_string = paste(this_warnings, collapse="&&&&&&")
  estimates = temp$coefficients[, 1]
  fixed_diffs = estimates - betas
  fixed_CI_l = temp$coefficients[, 1] - 1.96*temp$coefficients[, 2]
  fixed_CI_h = temp$coefficients[, 1] + 1.96*temp$coefficients[, 2]
  ci_range = fixed_CI_h - fixed_CI_l
  fixed_contained_in_95CI = (fixed_CI_l < betas) & ( betas < fixed_CI_h) 
  
  this_data = data.frame(run=run, names=beta_names, type="lmer", true_value=betas, estimate=estimates, fixed_diff=fixed_diffs, fixed_contained=fixed_contained_in_95CI, convergence_failed=lmer_failed, warnings=this_warning_string, ci_range=ci_range)
  model_data = bind_rows(model_data, this_data)
  
  this_warnings = c()
  withCallingHandlers({lmer_model_simplified = glmer(outcome ~ parameter_1 * (condition + parameter_2) + (1 | subject_id), data, family=binomial)}, warning=function(w) {this_warnings <<- c(this_warnings, w)})
  this_warning_string = paste(this_warnings, collapse="&&&&&&")
  lmer_simplified_failed = length(this_warnings) > 0
  estimates = temp$coefficients[, 1]
  fixed_diffs = estimates - betas
  fixed_CI_l = temp$coefficients[, 1] - 1.96*temp$coefficients[, 2]
  fixed_CI_h = temp$coefficients[, 1] + 1.96*temp$coefficients[, 2]
  ci_range = fixed_CI_h - fixed_CI_l
  fixed_contained_in_95CI = (fixed_CI_l < betas) & ( betas < fixed_CI_h) 
  
  this_data = data.frame(run=run, names=beta_names, type="lmer_no_slopes", true_value=betas, estimate=estimates, fixed_diff=fixed_diffs, fixed_contained=fixed_contained_in_95CI, convergence_failed=lmer_simplified_failed, warnings=this_warning_string, ci_range=ci_range)
  model_data = bind_rows(model_data, this_data)
  
  # brms

  this_warnings = c()
  withCallingHandlers({brm_model = brm(outcome ~ parameter_1 * (condition + parameter_2) + (1 + parameter_1 | subject_id), data, family=bernoulli)}, warning=function(w) {this_warnings <<- c(this_warnings, w)})
  brms_failed = length(this_warnings) > 0
  this_warning_string = paste(this_warnings, collapse="&&&&&&")

  temp = summary(brm_model)

  estimates = temp$fixed[, 1]
  fixed_diffs = estimates - betas
  fixed_contained_in_95CI = (temp$fixed[, 3] < betas) & ( betas < temp$fixed[, 4])
  ci_range = temp$fixed[, 4]- temp$fixed[, 3]

  this_data = data.frame(run=run, names=beta_names, type="brms", true_value=betas, estimate=estimates, fixed_diff=fixed_diffs, fixed_contained=fixed_contained_in_95CI, convergence_failed=brms_failed, warnings=this_warning_string, ci_range=ci_range)
  model_data = bind_rows(model_data, this_data)
  ## excluding random effects for now, fixed are more comparable across packages
  # random_diffs = temp$random$subject_id[1:2, 1] - noise_and_RE_sd
  # random_contained_in_95CI = (temp$random$subject_id[1:2, 3] < noise_and_RE_sd) & (noise_and_RE_sd < temp$random$subject_id[1:2, 4])
}
```

```{r}
write_csv(model_data, "model_results.csv")
```

# visualizing
```{r}
theme_set(theme_bw() +
            theme(panel.grid=element_blank()))
```

## does brms converge more often?


```{r}
ggplot(data=model_data, aes(x=type, y=1*convergence_failed, fill=type)) +
  geom_bar(stat="summary", fun.y="mean", position="dodge") +
  geom_errorbar(stat="summary", fun.data=mean_cl_normal, width=0.5, position=position_dodge(width=0.9)) +
  scale_fill_brewer(palette="Set2")+   
  labs(y="Convergence failures (%)")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## how biased are the estimates?

```{r}
ggplot(data=model_data, aes(x=names, y=abs(fixed_diff), fill=type)) +
  geom_bar(stat="summary", fun.y="mean", position="dodge") +
  geom_errorbar(stat="summary", fun.data=mean_cl_normal, width=0.5, position=position_dodge(width=0.9)) +
  scale_fill_brewer(palette="Set2")+ 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Are they less biased when no convergence (or other) warnings were issued?

```{r}
ggplot(data=model_data, aes(x=names, y=abs(fixed_diff), fill=type)) +
  geom_bar(stat="summary", fun.y="mean", position="dodge") +
  geom_errorbar(stat="summary", fun.data=mean_cl_normal, width=0.5, position=position_dodge(width=0.9)) +
  scale_fill_brewer(palette="Set2")+ 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  facet_grid(.~ convergence_failed, scales="free")
```

Individual results:

```{r}
ggplot(data=model_data, aes(x=fixed_diff, y=type, color=type)) +
  geom_point(position=position_jitter(width=0)) +
  scale_color_brewer(palette="Set2") + 
  facet_wrap(. ~ names)
```

```{r}
ggplot(data=model_data, aes(x=fixed_diff, y=type, color=type)) +
  geom_point(position=position_jitter(width=0)) +
  scale_color_brewer(palette="Set2") + 
  facet_wrap(convergence_failed ~ names, scales="free")
```

## Are estimate errors correlated?

They should be, but to what extent?

```{r}
ggplot(data=model_data %>%
         filter(type != "lmer_no_slopes") %>%
         select(run, names, type, fixed_diff) %>%
         spread(type, fixed_diff), aes(x=lmer, y=brms)) +
  geom_point() +
  facet_wrap(. ~ names)
```


## Are the CIs biased?

```{r}
ggplot(data=model_data, aes(x=names, y=1*fixed_contained, fill=type)) +
  geom_bar(stat="summary", fun.y="mean", position="dodge") +
  geom_errorbar(stat="summary", fun.data=mean_cl_normal, width=0.5, position=position_dodge(width=0.9)) +
  scale_fill_brewer(palette="Set2") +
  labs(x="Parameter", y="True value in 95%-C(r)I") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
ggplot(data=model_data, aes(x=names, y=1*fixed_contained, fill=type)) +
  geom_bar(stat="summary", fun.y="mean", position="dodge") +
  geom_errorbar(stat="summary", fun.data=mean_cl_normal, width=0.5, position=position_dodge(width=0.9)) +
  scale_fill_brewer(palette="Set2") +
  labs(x="Parameter", y="True value in 95%-C(r)I") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  facet_wrap(.~convergence_failed)
```

