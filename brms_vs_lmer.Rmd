---
title: "BRMS vs lmer comparison"
output:
  html_document:
    df_print: paged
---

```{r}
library(tidyverse)
library(lme4)
library(brms)
```

```{r}
num_runs = 2
num_subjects = 100
```

# making some data

```{r}
logistic = function(x) {
  return(1/(1+exp(-x)))
}
```


Predictors
```{r, echo=F, warning=T, error=T}

model_data = data.frame()
for (run in 1:num_runs) {
  set.seed(run)
  noise_and_RE_sd = 0.5
  subject_ids = 1:num_subjects
  subject_random_intercepts = rnorm(length(subject_ids), 0, noise_and_RE_sd)
  subject_p1_random_slopes = rnorm(length(subject_ids), 0, noise_and_RE_sd)
  trials = 1:20
  condition = c("A", "B") # between subjects
  parameter_2_values = c("U", "V")
  
  data = expand.grid(trial=trials, subject_id=subject_ids) %>%
    mutate(condition=cut(subject_id, c(1, num_subjects/2, num_subjects), labels=condition, include.lowest=T),
           parameter_1=runif(n(), -1, 1),
           parameter_2=sample(parameter_2_values, n(), replace=T),
           random_intercept=subject_random_intercepts[subject_id],
           p1_random_slope=subject_p1_random_slopes[subject_id],
           noise=rnorm(n(), 0, noise_and_RE_sd))
  
  intercept = rnorm(1, 0, 2)
  beta_p1 = rnorm(1, 0, 2)
  beta_cond= rnorm(1, 0, 2)
  beta_p1_x_cond = rnorm(1, 0, 2)
  beta_p2_is_V = rnorm(1, 0, 2)
  beta_p1_x_p2 = rnorm(1, 0, 2)
  betas = c(intercept, beta_p1, beta_cond, beta_p2_is_V, beta_p1_x_cond, beta_p1_x_p2)
  beta_names = c("(Intercept)", "parameter_1", "conditionB", "parameter_2V", "parameter_1:conditionB", "parameter_1:parameter_2V")
  
  # dv is a bernoulli trial
  
  data = data %>%
    mutate(
      logit = (intercept + (beta_p1 + p1_random_slope)*parameter_1 + beta_p2_is_V * (parameter_2 == "V") + beta_cond * (condition == "B") + beta_p1_x_cond * (parameter_1 * (condition == "B")) + beta_p1_x_p2 * (parameter_1 * (parameter_2 == "V"))),
      p = logistic(logit)) %>%
    rowwise() %>%
    mutate(outcome=rbinom(1, 1, p))
  
  # lmer
  
  lmer_model = glmer(outcome ~ parameter_1 * (condition + parameter_2) + (1 + parameter_1 | subject_id), data, family=binomial)
  temp = summary(lmer_model)
  lmer_failed = !is.null(temp$optinfo$conv$lme4$code) 
  estimates = temp$coefficients[, 1]
  fixed_diffs = estimates - betas
  fixed_CI_l = temp$coefficients[, 1] - 1.96*temp$coefficients[, 2]
  fixed_CI_h = temp$coefficients[, 1] + 1.96*temp$coefficients[, 2]
  fixed_contained_in_95CI = (fixed_CI_l < betas) & ( betas < fixed_CI_h) 
  
  this_data = data.frame(run=run, names=beta_names, type="lmer", true_value=betas, estimate=estimates, fixed_diff=fixed_diffs, fixed_contained=fixed_contained_in_95CI, convergence_failed=lmer_failed)
  model_data = bind_rows(model_data, this_data)
  
  
  lmer_model_simplified = glmer(outcome ~ parameter_1 * (condition + parameter_2) + (1 | subject_id), data, family=binomial)
  temp = summary(lmer_model_simplified)
  lmer_simplified_failed = !is.null(temp$optinfo$conv$lme4$code) 
  estimates = temp$coefficients[, 1]
  fixed_diffs = estimates - betas
  fixed_CI_l = temp$coefficients[, 1] - 1.96*temp$coefficients[, 2]
  fixed_CI_h = temp$coefficients[, 1] + 1.96*temp$coefficients[, 2]
  fixed_contained_in_95CI = (fixed_CI_l < betas) & ( betas < fixed_CI_h) 
  
  this_data = data.frame(run=run, names=beta_names, type="lmer_no_slopes", true_value=betas, estimate=estimates, fixed_diff=fixed_diffs, fixed_contained=fixed_contained_in_95CI, convergence_failed=lmer_simplified_failed)
  model_data = bind_rows(model_data, this_data)
  
  # brms
  
  brm_model = brm(outcome ~ parameter_1 * (condition + parameter_2) + (1 + parameter_1 | subject_id), data, family=bernoulli)
  temp = summary(brm_model)
  
  estimates = temp$fixed[, 1]
  fixed_diffs = estimates - betas
  fixed_contained_in_95CI = (temp$fixed[, 3] < betas) & ( betas < temp$fixed[, 4]) 
  
  this_data = data.frame(run=run, names=beta_names, type="brms", true_value=betas, estimate=estimates, fixed_diff=fixed_diffs, fixed_contained=fixed_contained_in_95CI, convergence_failed=F)
  model_data = bind_rows(model_data, this_data)
  ## excluding random effects for now, fixed are more comparable across packages
  # random_diffs = temp$random$subject_id[1:2, 1] - noise_and_RE_sd
  # random_contained_in_95CI = (temp$random$subject_id[1:2, 3] < noise_and_RE_sd) & (noise_and_RE_sd < temp$random$subject_id[1:2, 4])
}
```

# visualizing
```{r}
theme_set(theme_bw() +
            theme(panel.grid=element_blank()))
```


```{r}
ggplot(data=model_data, aes(x=names, y=abs(fixed_diff), fill=type)) +
  geom_bar(stat="summary", fun.y="mean", position="dodge") +
  scale_fill_brewer(palette="Set2")+ 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
ggplot(data=model_data, aes(x=names, y=1*fixed_contained, fill=type)) +
  geom_bar(stat="summary", fun.y="mean", position="dodge") +
  scale_fill_brewer(palette="Set2") +
  labs(x="Parameter", y="True value in 95%-C(r)I") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
ggplot(data=model_data %>%
         filter(type != "lmer_no_slopes") %>%
         select(run, names, type, fixed_diff) %>%
         spread(type, fixed_diff), aes(x=lmer, y=brms)) +
  geom_point() +
  facet_wrap(. ~ names)
```

